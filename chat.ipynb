{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Goal is to make the computer understand the language<br>\n",
    "\n",
    "Here are the steps\n",
    "\n",
    "1. Sentence segmentation\n",
    "2. Word tokenization\n",
    "3. Stemming\n",
    "4. Lemmatization\n",
    "5. Stop word analysis\n",
    "6. Dependency parsing\n",
    "7. Part-of-speech (POS) tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare a proper storage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet:\n",
    "    def __init__(self, count, hate_speech_count, offensive_language_count, neither_count, classs, tweet):\n",
    "        \"\"\"\n",
    "        - count (int): The total count of the tweet.\n",
    "        - hate (int): The count of hate speech in the tweet.\n",
    "        - offensive (int): The count of offensive language in the tweet.\n",
    "        - neither (int): The count of content classified as neither hate speech nor offensive.\n",
    "        - classs (str): The classification of the tweet.\n",
    "        - tweet (str): The text content of the tweet.\n",
    "        \"\"\"\n",
    "        self.count = count\n",
    "        self.hate = hate_speech_count\n",
    "        self.offensive = offensive_language_count\n",
    "        self.neither = neither_count\n",
    "        self.classs = classs\n",
    "        self.tweet = tweet\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.count} ; {self.hate} ; {self.offensive} ; {self.neither} ; {self.classs} ;; {self.tweet}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./archive/train.csv', 'r+') as file:\n",
    "    previous_line = ''\n",
    "\n",
    "    # Initialize a list to accumulate the modified content\n",
    "    final_content_lines = []\n",
    "\n",
    "    # Read and accumulate non-empty lines\n",
    "    for line in file:\n",
    "        stripped_line = line.strip()\n",
    "\n",
    "        if stripped_line and stripped_line[0].isdigit():\n",
    "            # If the current line is not empty and starts with an integer, accumulate it\n",
    "            final_content_lines.append(stripped_line)\n",
    "            previous_line = stripped_line\n",
    "        else:\n",
    "            # If the current line doesn't start with an integer, append it to the previous line\n",
    "            previous_line += stripped_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in final_content_lines:\n",
    "    \n",
    "    comma_indices = [index for index, char in enumerate(line) if char == ',']\n",
    "\n",
    "    # Extracting substrings between commas\n",
    "    count_str = line[0:comma_indices[0]].strip()\n",
    "    hate_str = line[comma_indices[0]+1:comma_indices[1]].strip()\n",
    "    offensive_str = line[comma_indices[1]+1:comma_indices[2]].strip()\n",
    "    neither_str = line[comma_indices[2]+1:comma_indices[3]].strip()\n",
    "    classs_str = line[comma_indices[3]+1:comma_indices[4]].strip()\n",
    "    tweet_str = line[comma_indices[4]+1:].strip()\n",
    "\n",
    "    # Converting to integers\n",
    "    count = int(count_str) if count_str.isdigit() else None\n",
    "    hate = int(hate_str) if hate_str.isdigit() else None\n",
    "    offensive = int(offensive_str) if offensive_str.isdigit() else None\n",
    "    neither = int(neither_str) if neither_str.isdigit() else None\n",
    "    classs = int(classs_str) if classs_str.isdigit() else None\n",
    "\n",
    "    # Creating an instance of the Tweet class\n",
    "    tweet_instance = Tweet(count, hate, offensive, neither, classs_str, tweet_str)\n",
    "\n",
    "    # Append the tweet instance to a list or do whatever you need to do with it\n",
    "    Tweets.append(tweet_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in Tweets[:10]:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tweet formatting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 ; 0 ; 0 ; 3 ; 2 ;; @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out.\n",
      "3 ; 0 ; 3 ; 0 ; 1 ;; @mleew17: boy dats cold.tyga dwn bad for cuffin dat hoe in the 1st place\n",
      "3 ; 0 ; 3 ; 0 ; 1 ;; @UrKindOfBrand Dawg @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit\n",
      "3 ; 0 ; 2 ; 1 ; 1 ;; @C_G_Anderson: @viva_based she look like a tranny\n",
      "6 ; 0 ; 6 ; 0 ; 1 ;; @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;\n",
      "3 ; 1 ; 2 ; 0 ; 1 ;; @T_Madison_x: The shit just blows me.claim you so faithful and down for somebody but still fucking with hoes &#128514;&#128514;&#128514;\n",
      "3 ; 0 ; 3 ; 0 ; 1 ;; @__BrighterDays: I can not just sit up and HATE on another bitch . I got too much shit going on\n",
      "3 ; 0 ; 3 ; 0 ; 1 ;; &#8220;@selfiequeenbri: cause I'm tired of you big bitches coming for us skinny girls&#8221;\n",
      "3 ; 0 ; 3 ; 0 ; 1 ;; &amp; you might not get ya bitch back &amp; thats that \n",
      "3 ; 1 ; 2 ; 0 ; 1 ;; @rhythmixx_ :hobbies include: fighting Mariam\n"
     ]
    }
   ],
   "source": [
    "for t in Tweets:\n",
    "    t.tweet = t.tweet.replace('RT', '').replace('!', '').replace('\"', '').replace(\"\\n\", '')\n",
    "    for _ in range(5):\n",
    "        t.tweet = t.tweet.replace('  ', ' ').replace('..', '.') # remove multiple points & space\n",
    "    \n",
    "for t in Tweets[:10]:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As **emojis** also have their meaning, i will extract them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = {}\n",
    "for t in Tweets:\n",
    "    emoji_indices = [match.start() for match in re.finditer(r'&#', t.tweet)]\n",
    "    for em in emoji_indices:\n",
    "        em += 2 # skip &#\n",
    "        end = em\n",
    "        while t.tweet[end].isdigit(): # go until the last digit\n",
    "            end += 1\n",
    "        emojis[t.tweet[em:end]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1581', '127867', '128700', '127817', '127827', '10060', '128066', '127481', '9898', '201', '127856', '128203', '128282', '127936', '8419', '128096', '128533', '1041233', '1043473', '58380', '127468', '127861', '128008', '65533', '127984', '9918', '127942', '127809', '128122', '187', '127770', '128025', '128588', '128581', '128179', '9749', '1043214', '127812', '9917', '128167', '8482', '1043350', '128133', '1590', '1041219', '128209', '128572', '127913', '160', '128270', '127837', '128549', '128174', '1041237', '57423', '127830', '9924', '128548', '1040788', '10024', '57933', '128054', '127805', '247', '776', '58399', '128094', '1041196', '176', '128683', '58407', '1043215', '9855', '1594', '127866', '65039', '1041205', '127880', '127382', '9995', '128077', '128524', '1043323', '128013', '8242', '128563', '128517', '128661', '128558', '128550', '127912', '128221', '128072', '128138', '127882', '128117', '128155', '8986', '1041204', '128058', '128665', '127379', '128518', '128184', '127806', '127480', '127877', '1585', '128275', '128560', '128519', '128252', '127796', '9835', '127810', '128127', '1605', '1043291', '127821', '128154', '128511', '128514', '127344', '128240', '9986', '128115', '9981', '127932', '1041629', '128559', '1043358', '9829', '9786', '128052', '128537', '127925', '1588', '128538', '128118', '9757', '128515', '128680', '127873', '10067', '127752', '127814', '128551', '127916', '128539', '128064', '128124', '128555', '8221', '128032', '128565', '128299', '127769', '1607', '10084', '128226', '128587', '1577', '128038', '128162', '128273', '128186', '128037', '128315', '128129', '128119', '127482', '128171', '10071', '128161', '9992', '281', '9733', '128526', '128640', '128048', '128151', '128574', '1042390', '128137', '128591', '128135', '128053', '127825', '128178', '10006', '241', '1041210', '128513', '193', '128176', '128091', '127844', '127940', '58400', '127831', '128293', '10068', '128078', '8217', '8216', '8413', '1589', '128541', '127807', '9825', '1043357', '9203', '1041185', '10052', '127470', '58373', '1042469', '128567', '127926', '9729', '1578', '128071', '128173', '128576', '127801', '128309', '128107', '128132', '1043353', '1041681', '128016', '1576', '128089', '128036', '128566', '128545', '128664', '127835', '128529', '1606', '246', '128142', '1604', '8594', '128149', '128535', '128540', '128684', '299', '128145', '128108', '127383', '128681', '128170', '128055', '128516', '128530', '127908', '127776', '1043359', '1041243', '8252', '128182', '128294', '127922', '128029', '128571', '128227', '127868', '128153', '1603', '127773', '128266', '128308', '128536', '128163', '128068', '127909', '128148', '128164', '128018', '128585', '128523', '128165', '1575', '128575', '128589', '127938', '128573', '128247', '237', '128195', '127463', '128076', '128123', '128214', '128139', '128679', '128553', '127969', '11093', '171', '128120', '127919', '127881', '128552', '127876', '127944', '128106', '1043351', '1591', '128047', '1041653', '232', '128143', '8220', '127917', '128556', '1571', '8226', '128131', '250', '127939', '127744', '128554', '127911', '127864', '58381', '128347', '169', '128125', '9996', '128069', '1574', '1041223', '127829', '128044', '128531', '9899', '1041190', '128158', '8230', '1608', '1041636', '127797', '128686', '128652', '127811', '127804', '128544', '128134', '128181', '9889', '128168', '128562', '58386', '1041184', '127754', '128073', '128056', '128586', '127874', '322', '1041222', '128035', '128027', '218', '128060', '11088', '127935', '127386', '128543', '128049', '58167', '9994', '128564', '8211', '127800', '128152', '1040784', '9832', '57608', '128590', '1041240', '161', '243', '128128', '9728', '128298', '128694', '180', '128111', '128522', '128121', '128569', '127946', '128272', '128175', '128075', '65292', '128527', '128169', '128141', '127378', '10004', '128532', '128570', '128690', '128677', '1043360', '128080', '128166', '1593', '128582', '128103', '128525', '128150', '128110', '1610', '128584', '57361', '128547', '225', '228', '233', '128074', '251', '128130', '128095', '128528', '128034', '128546', '128542', '1041216', '1583', '57607', '10069', '252', '127839', '1041191', '128081', '128521', '9697', '1586', '58382', '191', '127815', '1043293', '128114', '1548', '127775', '8212', '128534', '127795', '128070', '128079', '128520', '58385', '1043292', '127851', '128147', '127849', '127813', '128109', '127850', '128557', '128010', '128561', '128583', '1582', '128014'}\n"
     ]
    }
   ],
   "source": [
    "print((set(emojis.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input the keys in Chat-GPT and ask it to generate some **description** of the emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_mapping = {\n",
    "    57361: [57361],\n",
    "    128514: [128514, 128517, 128591, 128557, 128531, 128588, 128515, 128512, 128513, 128514, 128515, 128516, 128517, 128518, 128519, 128520, 128521, 128522, 128523, 128524, 128525, 128526, 128527, 128528, 128529, 128530, 128531, 128532, 128533, 128534, 128535, 128536, 128537, 128538, 128539, 128540, 128541, 128542, 128543, 128544, 128545, 128546, 128547, 128548, 128549, 128550, 128551, 128552, 128553, 128554, 128555, 128556, 128557, 128558, 128559, 128560, 128561, 128562, 128563, 128564, 128565, 128566, 128567, 128568, 128569, 128570, 128571, 128572, 128573, 128574, 128575, 128576, 128577, 128578, 128579, 128580, 128581, 128582, 128583, 128584, 128585, 128586, 128587, 128588, 128589, 128590, 128591],\n",
    "    128175: [128175, 128079],\n",
    "    128553: [128553],\n",
    "    128584: [128584],\n",
    "    128175: [128175],\n",
    "    128049: [128049],\n",
    "    128554: [128554],\n",
    "    128527: [128527],\n",
    "    128056: [128056],\n",
    "    128544: [128544],\n",
    "    128545: [128545],\n",
    "    128514: [128514]\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
