{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import spacy\n",
    "from keras.models import Sequential\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout, MaxPooling1D, Conv1D, Flatten\n",
    "from spacy import displacy\n",
    "import nltk\n",
    "from keras.datasets import imdb\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import text\n",
    "from nltk.parse.dependencygraph import DependencyGraph\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "import imdbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet:\n",
    "    def __init__(self, count, hate_speech_count, offensive_language_count, neither_count, classs, tweet):\n",
    "        \"\"\"\n",
    "        - count (int): The total count of the tweet.\n",
    "        - hate (int): The count of hate speech in the tweet.\n",
    "        - offensive (int): The count of offensive language in the tweet.\n",
    "        - neither (int): The count of content classified as neither hate speech nor offensive.\n",
    "        - classs (str): The classification of the tweet.\n",
    "        - tweet (str): The text content of the tweet.\n",
    "        \"\"\"\n",
    "        self.count = count\n",
    "        self.hate = hate_speech_count\n",
    "        self.offensive = offensive_language_count\n",
    "        self.neither = neither_count\n",
    "        self.classs = classs\n",
    "        self.tweet = tweet\n",
    "        self.stems = []\n",
    "        self.tokens = []\n",
    "        self.code = []\n",
    "        self.tags = []\n",
    "        self.t_code = []\n",
    "        self.presence_word = []\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.count} ; {self.hate} ; {self.offensive} ; {self.neither} ; {self.classs} ;; {self.tweet}\"\n",
    "    \n",
    "    def peacefullness(self):\n",
    "        return self.neither_count / self.count\n",
    "    \n",
    "    def offensiveness(self):\n",
    "        return self.offensive / self.count\n",
    "    \n",
    "    def hateness(self):\n",
    "        return self.hate / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = []\n",
    "\n",
    "with open('./archive/train.csv', 'r+') as file:\n",
    "    previous_line = ''\n",
    "\n",
    "    # Initialize a list to accumulate the modified content\n",
    "    final_content_lines = []\n",
    "\n",
    "    # Read and accumulate non-empty lines\n",
    "    for line in file:\n",
    "        stripped_line = line.strip()\n",
    "\n",
    "        if stripped_line and stripped_line[0].isdigit():\n",
    "            # If the current line is not empty and starts with an integer, accumulate it\n",
    "            final_content_lines.append(stripped_line)\n",
    "            previous_line = stripped_line\n",
    "        else:\n",
    "            # If the current line doesn't start with an integer, append it to the previous line\n",
    "            previous_line += stripped_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in final_content_lines:\n",
    "    \n",
    "    comma_indices = [index for index, char in enumerate(line) if char == ',']\n",
    "\n",
    "    # Extracting substrings between commas\n",
    "    count_str = line[0:comma_indices[0]].strip()\n",
    "    hate_str = line[comma_indices[0]+1:comma_indices[1]].strip()\n",
    "    offensive_str = line[comma_indices[1]+1:comma_indices[2]].strip()\n",
    "    neither_str = line[comma_indices[2]+1:comma_indices[3]].strip()\n",
    "    classs_str = line[comma_indices[3]+1:comma_indices[4]].strip()\n",
    "    tweet_str = line[comma_indices[4]+1:].strip()\n",
    "\n",
    "    # Converting to integers\n",
    "    count = int(count_str) if count_str.isdigit() else None\n",
    "    hate = int(hate_str) if hate_str.isdigit() else None\n",
    "    offensive = int(offensive_str) if offensive_str.isdigit() else None\n",
    "    neither = int(neither_str) if neither_str.isdigit() else None\n",
    "    classs = int(classs_str) if classs_str.isdigit() else None\n",
    "\n",
    "    # Creating an instance of the Tweet class\n",
    "    tweet_instance = Tweet(count, hate, offensive, neither, classs_str, tweet_str)\n",
    "\n",
    "    # Append the tweet instance to a list or do whatever you need to do with it\n",
    "    Tweets.append(tweet_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (X_train, y_train), (X_test, y_test) = imdbb.load_imdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 200\n",
    "maxlen = 200\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 100\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test  = []\n",
    "y_train = []\n",
    "y_test  = []\n",
    "\n",
    "for t in Tweets:\n",
    "    X_train.append(t.tweet)\n",
    "    if t.hateness() > 0:\n",
    "        y_train.append(1)\n",
    "    else:\n",
    "        y_train.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_matrix(X_train)\n",
    "X_test = tokenizer.texts_to_matrix(X_test)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.0 0 200 24783\n",
      "y positive percentage balance: 20.1468748739055\n"
     ]
    }
   ],
   "source": [
    "avg = 0 \n",
    "max = 0\n",
    "min = 0\n",
    "\n",
    "for i in X_train:\n",
    "    l = len(i)\n",
    "    if l > max:\n",
    "        max = l\n",
    "    if l < min:\n",
    "        min = l\n",
    "\n",
    "    avg += l\n",
    "\n",
    "avg /= len(X_train)\n",
    "\n",
    "print(f\"avg: {avg}, \\tmin: {min}, \\tmax: {max}, \\tlen(X_train): {len(X_train)}\")\n",
    "\n",
    "count = 0\n",
    "for i in y_train:\n",
    "    if i == 1:\n",
    "        count+=1\n",
    "\n",
    "\n",
    "print(\"y positive percentage balance:\", 100* count / len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,\n",
    "                    embedding_dims,\n",
    "                    input_length=maxlen))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(hidden_dims, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "                                        class_weight = \"balanced\",\n",
    "                                        classes = np.unique(y_train),\n",
    "                                        y = y_train                                                    \n",
    "                                    )\n",
    "class_weights = dict(zip(np.unique(y_train), class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "775/775 [==============================] - 84s 105ms/step - loss: 0.6693 - accuracy: 0.5988\n",
      "Epoch 2/10\n",
      "775/775 [==============================] - 79s 102ms/step - loss: 0.6273 - accuracy: 0.6860\n",
      "Epoch 3/10\n",
      "775/775 [==============================] - 80s 103ms/step - loss: 0.6132 - accuracy: 0.6985\n",
      "Epoch 4/10\n",
      "775/775 [==============================] - 73s 94ms/step - loss: 0.6011 - accuracy: 0.7097\n",
      "Epoch 5/10\n",
      "775/775 [==============================] - 62s 81ms/step - loss: 0.5868 - accuracy: 0.7163\n",
      "Epoch 6/10\n",
      "775/775 [==============================] - 65s 84ms/step - loss: 0.5778 - accuracy: 0.7228\n",
      "Epoch 7/10\n",
      "775/775 [==============================] - 66s 86ms/step - loss: 0.5664 - accuracy: 0.7317\n",
      "Epoch 8/10\n",
      "775/775 [==============================] - 67s 86ms/step - loss: 0.5577 - accuracy: 0.7389\n",
      "Epoch 9/10\n",
      "775/775 [==============================] - 68s 87ms/step - loss: 0.5497 - accuracy: 0.7419\n",
      "Epoch 10/10\n",
      "775/775 [==============================] - 69s 90ms/step - loss: 0.5369 - accuracy: 0.7460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7efe8efc3ca0>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1, class_weight=class_weights) # validation_data=(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antoine/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('models/hate-v3-CNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
